# -*- coding: utf-8 -*-
"""assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1drrZihD8p6x3ahwo2AvkkBAZ7nonZ907
"""

# -*- coding: utf-8 -*-
"""
coffee_classification.py
"""
!pip install wikipedia-api spacy scikit-learn

import wikipediaapi
import spacy
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report
import logging

#logging for debugging purposes#
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

#Function to retrieve the text of a Wikipedia page using a custom user-agent
def fetch_wikipedia_page(title):
    try:
        #using the user-agent to avoid blocking from Wikipedia
        user_agent = "your-unique-user-agent"
        headers = {
            'User-Agent': user_agent
        }
        wiki_wiki = wikipediaapi.Wikipedia('en', headers=headers)
        page = wiki_wiki.page(title)
        if page.exists():
            logging.info(f"Successfully fetched page: {title}")
            return page.text
        else:
            logging.warning(f"Page '{title}' does not exist.")
            return ""
    except Exception as e:
        logging.error(f"An error occurred while fetching the page '{title}': {str(e)}")
        return ""

# Function to prepare and fetch data
def collect_data():
    # Sample Of coffee-related topics
    coffee_titles = ["Coffee", "Coffee production", "Coffee bean", "Arabica coffee"]

    # Sample Of non-coffee-related topics
    non_coffee_titles = ["Paris", "Photosynthesis", "Quantum Mechanics", "Shakespeare"]

    coffee_texts = [fetch_wikipedia_page(title) for title in coffee_titles]
    non_coffee_texts = [fetch_wikipedia_page(title) for title in non_coffee_titles]

    # Combining texts and labels
    texts = coffee_texts + non_coffee_texts
    labels = ["coffee"] * len(coffee_texts) + ["non-coffee"] * len(non_coffee_texts)

    return texts, labels

# Function to train the model
def train_model(texts, labels):
    # Split the dataset into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

    # Create a pipeline that combines TfidfVectorizer and Naive Bayes classifier
    model = make_pipeline(TfidfVectorizer(), MultinomialNB())

    # Train the model
    model.fit(X_train, y_train)

    # Evaluate the model on the test set
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred)

    logging.info("Model training completed.")
    print("Classification Report:\n", report)

    return model

def classify_text(model, text):
    return model.predict([text])[0]

# Main function to execute the pipeline
def main():
    #Collecting data from Wikipedia
    texts, labels = collect_data()

    #Training the model
    model = train_model(texts, labels)

    #Classifying new text
    new_text = "Coffee is a brewed drink prepared from roasted coffee beans, the seeds of berries from certain Coffea species."
    result = classify_text(model, new_text)
    print(f"The text is classified as: {result}")

# Execute the main function
if __name__ == "__main__":
    main()